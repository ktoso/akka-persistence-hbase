hbase-journal {

  # class name of the hbase journal plugin
  class = "akka.persistence.hbase.journal.HBaseAsyncWriteJournal"

  # Partitions will be used to avoid the "hot write region" problem.
  # Set this to a number greater than the expected number of regions of your table.
  # WARNING: It is not supported to change the partition count when already written to a table (could miss some records)
  partition.count = 50

  # All these settings will be set on the underlying Hadoop Configuration
  hbase {
    hbase.zookeeper.quorum = "localhost:2181"
    zookeeper.znode.parent = "/hbase"
  }

  # Name of the table to be created/used by the journal
  table = "messages"

  # Name of the family to be created/used by the journal
  family = "akka"

  # When performing scans, how many items to we want to obtain per one next(N) call.
  # This most notably affects the speed at which message replay progresses, fine tune this to match your cluster.
  scan-batch-size = 200

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"

  # Default dispatcher used by plugin
  plugin-dispatcher = "akka-hbase-persistence-dispatcher"

  # Internal events published to the eventStream.
  publish-testing-events = off

  # Write batch size configuration is self to akka-persistence, refer to:
  # http://doc.akka.io/docs/akka/2.3.0-RC1/scala/persistence.html#batch-writes
  # Settings are defined per-operation:
  # akka.persistence.journal.max-message-batch-size
  # akka.persistence.journal.max-confirmation-batch-size
  # akka.persistence.journal.max-deletion-batch-size
  #
  # Flushes occur after every batch operation, for example for a batch 200 msgs, we'll flush right away, but may happen more often.
}

hadoop-snapshot-store {
  # class name of snapshot plugin
  class = "akka.persistence.hbase.snapshot.HadoopSnapshotStore"

  # select your prefered implementation based on your needs
  #
  # * HDFS - can handle HUGE snapshots; Can be easily dumped to local filesystem using Hadoop CL tools
  #   impl = "akka.persistence.hbase.snapshot.HdfsSnapshotter"
  #
  # * HBase - snapshots stored together with snapshots; Snapshot size limited by Int.MaxValue bytes (currently) TODO lift limit?
  #   impl = "akka.persistence.hbase.snapshot.HBaseSnapshotter"

  # directory on HDFS where to store snapshots
  snapshot-dir = "/akka-persistence-snapshots"
}

akka-hbase-persistence-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    core-pool-size-min = 2
    core-pool-size-factor = 2.0
    core-pool-size-max = 10
  }
  throughput = 100
}
